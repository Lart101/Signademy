# ğŸ¤Ÿ Signademy

**AI-powered sign language learning app with real-time gesture detection**

Signademy is a React Native mobile application that uses advanced AI technology to help users learn sign language through real-time gesture detection and recognition.

## âœ¨ Features

- ğŸ¤– **Real-time AI Detection** - Uses MediaPipe and custom ASL model for accurate gesture recognition
- ğŸ“± **Cross-platform** - Built with React Native and Expo for iOS and Android
- ğŸ¨ **Beautiful UI** - Kid-friendly design with smooth animations
- ğŸ“· **Camera Integration** - Front/back camera switching with optimized capture
- ğŸ”„ **Live Feedback** - Instant gesture recognition with confidence scores
- â™¿ **Accessible** - Designed for all ages and abilities
- ğŸš€ **Performance Optimized** - Throttled processing for smooth experience

## ğŸ› ï¸ Technical Stack

- **Frontend**: React Native 0.79.5
- **Framework**: Expo SDK 53
- **Camera**: expo-camera 16.1.10
- **AI/ML**: MediaPipe Tasks Vision 0.10.3
- **WebView**: react-native-webview 13.13.5
- **Model Storage**: Supabase
- **Architecture**: Modular component-based structure

## ğŸ“ Project Structure

```
Signademy/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/          # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ SplashScreen.js  # Animated splash screen
â”‚   â”‚   â”œâ”€â”€ LoadingOverlay.js # Loading and error states
â”‚   â”‚   â”œâ”€â”€ CameraView.js    # Camera component
â”‚   â”‚   â”œâ”€â”€ DetectionWebView.js # MediaPipe WebView
â”‚   â”‚   â””â”€â”€ CameraControls.js # Camera control buttons
â”‚   â”œâ”€â”€ hooks/               # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ useCameraHooks.js # Camera permissions & capture
â”‚   â”‚   â””â”€â”€ useModelState.js # AI model state management
â”‚   â”œâ”€â”€ styles/              # Centralized styling
â”‚   â”‚   â””â”€â”€ MainStyles.js    # All StyleSheet objects
â”‚   â””â”€â”€ webview/             # WebView content
â”‚       â””â”€â”€ MediaPipeHTML.js # HTML for MediaPipe integration
â”œâ”€â”€ assets/                  # App icons and images
â”œâ”€â”€ App.js                  # Main application component
â”œâ”€â”€ package.json            # Dependencies and scripts
â””â”€â”€ app.json               # Expo configuration
```

## ğŸš€ Getting Started

### Prerequisites

- Node.js (14 or higher)
- npm or yarn
- Expo CLI
- iOS Simulator or Android Emulator (for testing)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Lart101/Signademy.git
   cd Signademy
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Start the development server**
   ```bash
   npm start
   # or
   expo start
   ```

4. **Run on device/emulator**
   - Scan QR code with Expo Go app (mobile)
   - Press `a` for Android emulator
   - Press `i` for iOS simulator
   - Press `w` for web browser

## ğŸ“± Usage

1. **Launch the app** - Beautiful splash screen with Signademy branding
2. **Grant camera permission** - Required for gesture detection
3. **Enable camera** - Use the camera toggle button
4. **Start signing** - Make ASL gestures in front of the camera
5. **View results** - Real-time detection with confidence scores
6. **Switch camera** - Use flip button to change between front/back camera

## ğŸ¤– AI Model

Signademy uses a custom-trained ASL (American Sign Language) model:

- **Training Data**: 14,000+ ASL gesture images
- **Model Format**: MediaPipe Task format (.task)
- **Hosting**: Supabase cloud storage
- **Recognition**: Real-time gesture classification with confidence scores
- **Performance**: Optimized for mobile devices with GPU acceleration

## ğŸ¨ Design Features

- **Splash Screen**: Animated logo with feature highlights
- **Loading States**: Professional loading overlays during AI model initialization
- **Error Handling**: User-friendly error messages with retry functionality
- **Responsive Design**: Adapts to different screen sizes
- **Accessibility**: High contrast colors and clear typography
- **Smooth Animations**: React Native Animated API for fluid transitions

## ğŸ”§ Configuration

### Camera Settings
- **Quality**: Optimized for performance (0.3 quality)
- **Capture Interval**: 500ms for smooth detection
- **Format**: JPEG with base64 encoding
- **Features**: Front/back switching, permission management

### AI Processing
- **Throttling**: 300ms minimum between AI processing
- **GPU Acceleration**: Enabled for better performance
- **Model Loading**: Automatic retry on failure
- **Results Display**: Confidence threshold filtering

## ğŸ“Š Performance

- **Bundle Size**: ~7MB total
- **Startup Time**: ~2-3 seconds
- **AI Model Load**: ~3-5 seconds (network dependent)
- **Frame Processing**: 500ms intervals
- **AI Processing**: 300ms throttled
- **Memory Usage**: Optimized for mobile devices

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Team

**Signademy Team** - AI-powered education technology

## ğŸ™ Acknowledgments

- MediaPipe team for the AI/ML framework
- Expo team for the development platform
- React Native community for the mobile framework
- ASL community for gesture recognition insights

## ğŸ“ Support

For support, please open an issue on GitHub or contact the development team.

---

**Made with â¤ï¸ for accessible education**

ğŸ¤Ÿ **Signademy** - Making sign language learning accessible to everyone through AI technology.
